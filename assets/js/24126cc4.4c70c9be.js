"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[7192],{5368:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"sdk-documentation/android-sdk/tutorial","title":"Tutorial","description":"1. Prerequisites","source":"@site/docs/5-sdk-documentation/1-android-sdk/2-tutorial.md","sourceDirName":"5-sdk-documentation/1-android-sdk","slug":"/sdk-documentation/android-sdk/tutorial","permalink":"/dev-book/sdk-documentation/android-sdk/tutorial","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Quick Start","permalink":"/dev-book/sdk-documentation/android-sdk/quick-start"},"next":{"title":"Core Concepts","permalink":"/dev-book/sdk-documentation/android-sdk/core-concepts"}}');var s=i(4848),r=i(8453);const a={sidebar_position:2},l="Tutorial",d={},o=[{value:"1. Prerequisites",id:"1-prerequisites",level:2},{value:"2. Installing SDK",id:"2-installing-sdk",level:2},{value:"3. Initializing SDK",id:"3-initializing-sdk",level:2},{value:"4. Streaming Live",id:"4-streaming-live",level:2},{value:"5. Controlling Live Streaming",id:"5-controlling-live-streaming",level:2},{value:"6. Chatting in Live",id:"6-chatting-in-live",level:2},{value:"7. Ending Live Streaming",id:"7-ending-live-streaming",level:2},{value:"8. Watching Live",id:"8-watching-live",level:2}];function c(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"tutorial",children:"Tutorial"})}),"\n",(0,s.jsx)(n.h2,{id:"1-prerequisites",children:"1. Prerequisites"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Requirement"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Android SDK 24 or higher"}),"\n",(0,s.jsx)(n.li,{children:"Kotlin 1.6 or higher"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Creating application"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"To use the SDK, you must first sign up for a membership in the user console on the web and then create an application. Direct membership is currently limited. If you would like to sign up, please contact Jocoos."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Getting access token from server"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"You need an access token to use the SDK. The application server uses the FlipFlop Cloud API to get an access token and passes it to the client"}),"\n",(0,s.jsxs)(n.li,{children:["For more information on using the API, refer the ",(0,s.jsx)(n.a,{href:"https://jocoos-public.github.io/dev-book/jekyll/2023-10-16-App-Member-API.html#member-login",children:"FlipFlop Cloud - Member Login API"})," documentation."]}),"\n",(0,s.jsx)(n.li,{children:"For more information about access tokens, see the Authentication section of Core Concepts"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2-installing-sdk",children:"2. Installing SDK"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"You need to specify the repository to get the FlipFlop Cloud Android SDK from."}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Depending on the version of Gradle you're using, the location of the code you need to add may vary."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Add the following to settings.gradle if you are using Gradle 6.8 or later, or to build.gradle if you are using Gradle 6.7 or earlier"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// settings.gradle\n// Gradle 6.8 or higher\ndependencyResolutionManagement {\n    repositories {\n        maven { url 'https://jitpack.io' }\n    }\n}\n\n// build.gradle\n// Gradle 6.7 or lower\nallprojects {\n    repositories {\n        maven { url 'https://jitpack.io' }\n    }\n}\n\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Add the code below to the build.gradle of the module you want to use the SDK for."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"dependencies {\n  implementation(\u2018com.jocoos.jocoos-public:ff-lite-android-sdk:1.8.2\u2019) {\n    transitive = true\n  }\n}\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"App permissions are required to use the SDK. Add the content below to your AndroidManifest.xml."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<uses-permission android:name="android.permission.INTERNET"/>\n<uses-permission android:name="android.permission.CAMERA"/>\n<uses-permission android:name="android.permission.RECORD_AUDIO"/>\n<uses-permission\n    android:name="android.permission.WRITE_EXTERNAL_STORAGE"\n    tools:ignore="ScopedStorage" />\n<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE"\n    android:maxSdkVersion="32" />\n<uses-permission android:name="android.permission.ACCESS_NETWORK_STATE"/>\n<uses-permission android:name="android.permission.READ_MEDIA_IMAGES" />\n\n<uses-feature android:name="android.hardware.camera.autofocus"/>\n<uses-feature\n    android:name="android.hardware.camera"\n    android:required="false" />\n'})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"You must obtain the relevant permissions before going live"}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["\ucc38\uace0: ",(0,s.jsx)(n.a,{href:"https://developer.android.com/training/permissions/requesting",children:"Android Runtime Permission"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The example below is a code snippet for a permission request"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"private var permissions = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.TIRAMISU) {\n    arrayOf(\n        Manifest.permission.INTERNET,\n        Manifest.permission.CAMERA,\n        Manifest.permission.RECORD_AUDIO,\n        Manifest.permission.READ_MEDIA_IMAGES,\n    )\n} else {\n    arrayOf(\n        Manifest.permission.INTERNET,\n        Manifest.permission.CAMERA,\n        Manifest.permission.RECORD_AUDIO,\n        Manifest.permission.READ_EXTERNAL_STORAGE,\n    )\n}\nprivate var permissionGranted = false\n\noverride fun onCreate(savedInstanceState: Bundle?) {\n    super.onCreate(savedInstanceState)\n\n    permissionGranted = requestPermission(permissions)\n}\n\noverride fun onRequestPermissionsResult(\n    requestCode: Int,\n    permissions: Array<out String>,\n    grantResults: IntArray\n) {\n    super.onRequestPermissionsResult(requestCode, permissions, grantResults)\n    permissionGranted =\n        grantResults.isNotEmpty() && grantResults.all { it == PackageManager.PERMISSION_GRANTED }\n    when (requestCode) {\n        PERMISSIONS_REQUEST -> {\n            if (permissionGranted) {\n                initialized()\n            } else {\n                // need live permission\n            }\n        }\n        else -> {\n\n        }\n    }\n}\n\nprivate fun requestPermission(permissions: Array<String>): Boolean {\n     var mustRequest = false\n    for (permission in permissions) {\n        if (ContextCompat.checkSelfPermission(this, permission) != PackageManager.PERMISSION_GRANTED) {\n            mustRequest = true\n            break\n        }\n    }\n    if (mustRequest) {\n        ActivityCompat.requestPermissions(this, permissions, PERMISSIONS_REQUEST)\n        }\n    return !mustRequest\n}\n\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"3-initializing-sdk",children:"3. Initializing SDK"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Before you can use the features provided by the SDK, you need to initialize the SDK. Add the code below to your application's onCreate()."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// connect to flipflop dev server\nval server = FFLServer.DEV\nFlipFlopLite.initialize(context = applicationContext, server = server)\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"4-streaming-live",children:"4. Streaming Live"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Create a StreamingFragment class that corresponds to a screen for live broadcasting and a View for it, streaming_fragment.xml."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"In streaming_fragment.xml, create an FFLStreamingView, which is the View for the live broadcast. (The following will take up the entire camera screen."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0" encoding="utf-8"?>\n<androidx.constraintlayout.widget.ConstraintLayout\n   xmlns:android="http://schemas.android.com/apk/res/android"\n   xmlns:app="http://schemas.android.com/apk/res-auto"\n   xmlns:tools="http://schemas.android.com/tools"\n   android:layout_width="match_parent"\n   android:layout_height="match_parent">\n\n  <com.jocoos.flipflop.view.FFLStreamingView\n     android:id="@+id/streamingView"\n     android:layout_width="match_parent"\n     android:layout_height="match_parent"\n     android:background="@color/black"\n     app:layout_constraintBottom_toBottomOf="parent"\n     app:layout_constraintTop_toTopOf="parent" />\n\n</androidx.constraintlayout.widget.ConstraintLayout>\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Create an FFLStreamer instance in the StreamingFragment. In ACCESS_TOKEN, put the token you received via the FlipFlop Cloud API"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingFragment : Fragment() {\n    private var streamer: FFLStreamer? = null\n\n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        val streamer = FlipFlopLite.getStreamer(ACCESS_TOKEN)\n    }\n}\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Call the prepare() function to initialize the FFLStreamer. The prepare() function takes an FFLStreamingView as its first parameter and an FFStreamerConfig as its second parameter."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"You can set the following in FFStreamerConfig"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"key"}),(0,s.jsx)(n.th,{children:"description"}),(0,s.jsx)(n.th,{children:"default"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"width"}),(0,s.jsx)(n.td,{children:"video width"}),(0,s.jsx)(n.td,{children:"1280"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"height"}),(0,s.jsx)(n.td,{children:"video height"}),(0,s.jsx)(n.td,{children:"720"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"videoBitrate"}),(0,s.jsx)(n.td,{children:"video bitrate"}),(0,s.jsx)(n.td,{children:"3000 * 1024"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"keyFrameInterval"}),(0,s.jsx)(n.td,{children:"key frame interval"}),(0,s.jsx)(n.td,{children:"2"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"fps"}),(0,s.jsx)(n.td,{children:"framerate"}),(0,s.jsx)(n.td,{children:"30"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"sampleRate"}),(0,s.jsx)(n.td,{children:"audio samplerate"}),(0,s.jsx)(n.td,{children:"48000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"audioBitrate"}),(0,s.jsx)(n.td,{children:"audio bitrate"}),(0,s.jsx)(n.td,{children:"128 * 1024"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"cameraPos"}),(0,s.jsx)(n.td,{children:"camera back or front"}),(0,s.jsx)(n.td,{children:"front"})]})]})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingFragment : Fragment() {\n    private var streamer: FFLStreamer? = null\n\n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        val streamer = FlipFlopLite.getStreamer(accessToken)\n        streamer?.prepare(requireContext(), binding.streamingView, FFStreamerConfig(videoBitrate = 2000 * 1024, fps = 30, sampleRate = 44100))\n    }\n}\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Set a title for the live."}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"The title of the live to show when importing the live list."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:'val title = "This is live!"\nstreamer?.setVideoInfo(title)\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Connect an event to receive information that notifies your app during a live broadcast"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'Of the supported events, we\'ll only connect to the following for this tutorial. For a detailed description of the individual items, see "Handling Events" in "3. Core Concepts".'}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"event"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"StreamerStateChanged"}),(0,s.jsx)(n.td,{children:"notify the state of FFStreamer"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"BroadcastStateChanged"}),(0,s.jsx)(n.td,{children:"notify the state of media streaming"})]})]})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingFragment : Fragment() {\n    private var streamer: FFLStreamer? = null\n\n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        val streamer = FlipFlopLite.getStreamer(accessToken).apply {\n            prepare(requireContext(), binding.streamingView)\n        }\n        \n        lifecycleScope.launch {\n            streamer?.streamerEvent.collect { event ->\n                when (event) {\n                    is StreamerEvent.StreamStateChanged -> {\n                        when (event.state) {\n                            StreamState.PREPARED -> {\n                                // streaming is prepared\n                            }\n                            StreamState.STARTED -> {\n                                // streaming is started\n                            }\n                            StreamState.STOPPED -> {\n                                // streaming is stopped\n                            }\n                            StreamState.CLOSED -> {\n                                // streaming is closed\n                            }\n                        }\n                    }\n                    is StreamerEvent.LiveExists -> {\n                        // exists video room that is not closed\n                        // decide whether or not restarting previous live\n                    }\n                    is StreamerEvent.StreamerError -> {\n                        // handle error\n                    }\n                    else -> {\n                        // ignore at the moment\n                    }\n                }\n            }\n        }\n    }\n}\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"StreamerState Event"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"state"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"PREPARED"}),(0,s.jsx)(n.td,{children:"notify that you are ready to go live"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"STARTED"}),(0,s.jsx)(n.td,{children:"notify that you that your live stream has started. This status does not mean that viewers can see you live."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"STOPPED"}),(0,s.jsx)(n.td,{children:"Notify that the live stream has been interrupted."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CLOSED"}),(0,s.jsx)(n.td,{children:"Notify that the live has ended."})]})]})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"BroadcastState Event"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"state"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"ACTIVE"}),(0,s.jsx)(n.td,{children:"notify that the live is in progress (meaning viewers can see the live)."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"INACTIVE"}),(0,s.jsx)(n.td,{children:"notify that your live has been interrupted (meaning viewers are unable to watch your live)."})]})]})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"Difference between StreamerState and BroadcastState: StreamerState refers to the state of the FFLStreamer locally, while BroadcastState refers to whether the media server is streaming normally."}),"\n",(0,s.jsx)(n.p,{children:"If the live broadcast started successfully, events should occur in the following order"}),"\n",(0,s.jsx)(n.p,{children:": StreamerState.PREPARED -> StreamerState.STARTED -> BroadcastState.ACTIVE"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Starting Live Streaming"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"When you start a live transmission, you call the enter() and start() functions. The enter() function is called first to tell the FlipFlop Cloud server that you want to go live. Then, you call the start() function to start streaming to the media server."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"Checking if you're streaming normally: When you call the start() function, the StreamerState.STARTED event is fired first, followed by the BroadcastState.ACTIVE event a short time later."}),"\n",(0,s.jsx)(n.p,{children:"There may be some time between STARTED and ACTIVE, so it's a good idea to show the user that it's in progress with a UI in between."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// start chatting\nstreamer?.enter()\n// start streaming\nstreamer?.start()\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"5-controlling-live-streaming",children:"5. Controlling Live Streaming"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Controlling Camera"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Providing camera controls similar to those provided by the Camera app"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"let liveManager = streamer?.liveManager()\n// switch camera\nliveManager?.switchCamera()\n"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"method"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"switchCamera"}),(0,s.jsx)(n.td,{children:"switch between camera front and back"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"videoMirror"}),(0,s.jsx)(n.td,{children:"switch camera mirror"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"zoom"}),(0,s.jsx)(n.td,{children:"setting camera zoom"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"setPointOfInterest"}),(0,s.jsx)(n.td,{children:"camera focus"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"enableAutoFocus"}),(0,s.jsx)(n.td,{children:"start auto focus"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"disableAutoFocus"}),(0,s.jsx)(n.td,{children:"end auto focus"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"tapToFocus"}),(0,s.jsx)(n.td,{children:"setting manual focus"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"getExposureCompensationRange"}),(0,s.jsx)(n.td,{children:"getting camera exposure info(min, max, step for setting)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"exposureCompensation"}),(0,s.jsx)(n.td,{children:"setting camera exposure"})]})]})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Mute video or audio"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Provides a function that does not send audio or video","\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"When you don't want to send video, you call the muteVideo() function. You can tell if you are currently muting audio or not with the isAudioMuted() function."}),"\n",(0,s.jsx)(n.li,{children:"When you don't want to send audio, you call the muteAudio() function. The isVideoMuted() function tells us whether the video is currently mute or not."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"streamer?.liveManager()?.muteAudio(true)\n// or\nstreamer?.liveManager()?.muteVideo(true)\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Applying filters"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["We offer five filters below for a variety of video effects","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"TONE_DARK, TONE_DRAMATIC_COOL, TONE_VIVID_DARK, TONE_VIVID_WARM, TONE_WARM"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// apply dark filter\nstreamer?.liveManager()?.setFilter(TONE_DARK)\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Applying Image Effect"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Provides the ability to composite animated GIFs over live footage."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"Example: If you're selling a product and it's out of stock, you could include a fun animated out-of-stock image in your video."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// load animated gif from raw directory\nval inputStream: InputStream = resources.openRawResource(GIF_RES_ID)\nval scaleMode = FFScaleMode.NONE\nstreamer?.liveManager()?.setOverlayImage(inputStream, scaleMode)\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Adjusting bitrate"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"If you don't want to manually adjust the bitrate and want it to do it automatically, you can set the adaptiveBitrate value with the enableAdaptiveBitrate() function. If you call the disableAdaptiveBitrate() function, the SDK will automatically adjust the bitrate according to the network conditions, and the live broadcast will be at a fixed bitrate value regardless of the network"}),"\n",(0,s.jsx)(n.li,{children:"Before we went live, we could specify the bitrate as a parameter to the prepare() function (FFStreamerConfig). You can also change the bitrate after you go live: you can specify a value in the setVideoBitrateOnFly() function, which will change the bitrate of the video. Use this if you want it to always run at a fixed bitrate, or if your network is bad and you want to broadcast at a lower bitrate."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// apply adaptive bitrate\nstreamer?.liveManager()?.enableAdaptiveBitrate()\n// or\nstreamer?.liveManager()?.disableAdaptiveBitrate()\n\n// apply video bitrate\nlet bitrate = 3000 * 1024\nstreamer?.liveManager()?.setVideoBitrateOnFly(bitrate)\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Showing image"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The showImage() function is used to show an image in the middle of a live broadcast, and the hideImage() function is used to remove the image and show the camera screen again."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"You can specify an animation when showing an image. The following animations are available"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"animation"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"NONE"}),(0,s.jsx)(n.td,{children:"Shows the image directly without animation."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"FADE_IN_OUT"}),(0,s.jsx)(n.td,{children:"The camera screen will fade out and the image will fade in."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"SLIDE_TO_LEFT"}),(0,s.jsx)(n.td,{children:"The camera screen disappears to the left, and the image appears on the right."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"SLIDE_TO_TOP"}),(0,s.jsx)(n.td,{children:"The camera screen disappears above, and the image appears below."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"SLIDE_TO_CAMERA_BOTTOM"}),(0,s.jsx)(n.td,{children:"The camera screen will be lowered by the specified percentage (cameraRatio) and the image will be raised by the specified percentage."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"FADE_IN_PIP"}),(0,s.jsx)(n.td,{children:"The image will gradually appear and the camera screen will show it at the size (pipRatio) and position (pipTop, pipRight) you specify."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"ENTER_TOP"}),(0,s.jsx)(n.td,{children:"The camera screen fades away, and the image appears from above."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"ENTER_FADE_IN"}),(0,s.jsx)(n.td,{children:"The camera screen immediately disappears, and the image gradually appears."})]})]})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Other parameters are described below."}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Parameter"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"duration"}),(0,s.jsx)(n.td,{children:"Specifies the duration of the animation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"pipTop"}),(0,s.jsxs)(n.td,{children:["Specifies how far the camera screen should be positioned from the top of the View when using FADE_IN_PIP.",(0,s.jsx)("br",{}),"It is specified as a ratio to the height of the View (0.0 to 1.0f)",(0,s.jsx)("br",{}),"Example: If set to 0.1, the camera screen will be positioned at a distance of 10% of the height of the View from the top"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"pipRight"}),(0,s.jsxs)(n.td,{children:["Specifies how far the camera screen should be positioned from the right side of the View when using FADE_IN_PIP",(0,s.jsx)("br",{}),"It is specified as a ratio to the width of the View (0.0 to 1.0f)",(0,s.jsx)("br",{}),"Example: If set to 0.2, the camera screen will be positioned at a distance of 20% of the width of the View from the right side"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"pipRatio"}),(0,s.jsxs)(n.td,{children:["Specifies how much to shrink the camera screen when using FADE_IN_PIP",(0,s.jsx)("br",{}),"It is specified as a ratio to the entire size of the View (0.0 to 1.0f)",(0,s.jsx)("br",{}),"Example: If set to 0.2, the camera screen will be reduced to 20% of the size compared to the entire View"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"cameraRatio"}),(0,s.jsxs)(n.td,{children:["Specifies when using the SLIDE_TO_CAMERA_BOTTOM animation effect",(0,s.jsx)("br",{}),"It is specified as a ratio to the entire size of the View (0.0 to 1.0f)",(0,s.jsx)("br",{}),"Example: If set to 0.7, the camera screen will occupy 70% of the entire View at the bottom, and the top 30% of the View will display the image"]})]})]})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Ex: ENTER_TOP"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"val bitmap: Bitmap = BITMAP_IMAGE\nval transitionParams = FFTransitionParams(\n    transitionType = FFTransitionType.ENTER_TOP,\n    duration = 1000\n)\nstreamer?.liveManager()?.showImage(bitmap, FFScaleMode.CENTER_FIT, transitionParams)\n\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Ex: FADE_IN_PIP"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"val bitmap: Bitmap = BITMAP_IMAGE\nval transitionParams = FFTransitionParams(\n    transitionType = FFTransitionType.ENTER_TOP,\n    duration = 1000,\n    pipTop = 0.2,\n    pipRight = 0.2,\n    pipRatio = 0.2\n)\nstreamer?.liveManager()?.showImage(bitmap, FFScaleMode.CENTER_FIT, transitionParams)\n\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"6-chatting-in-live",children:"6. Chatting in Live"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Send a message: You can send a chat message by calling the sendMessage() function. This is a suspend function, so you need to call it inside a coroutine."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:'val message = "Hello!"\nstreamer?.liveChat().sendMessage(message)\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Receiving a message: When a message comes in, the MessageReceived event is fired on the FFLStreamer's streamerEvent."}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"event"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsx)(n.tbody,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"MessageReceived"}),(0,s.jsx)(n.td,{children:"Notify you that a chat message has come in."})]})})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"When the MessageReceived event occurs, handle messages sent by other users as follows."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingFragment : Fragment() {\n    ...\n\n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        ...\n        \n        lifecycleScope.launch {\n            streamer?.streamerEvent.collect { event ->\n                when (event) {\n                    ...\n                    is StreamerEvent.MessageReceived -> {\n                        handleMessage(event.message)\n                    }\n                    ...\n                }\n            }\n        }\n    }\n    \n    private fun handleMessage(message: FFLMessage) {\n        when (message.origin) {\n            Origin.MEMBER -> {\n                // message sent by member\n            }\n            else -> {\n                // ignore at the moment\n            }\n        }\n    }\n}\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The content of an FFLMessage is as follows"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"field"}),(0,s.jsx)(n.th,{children:"description"}),(0,s.jsx)(n.th,{children:"note"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"origin"}),(0,s.jsx)(n.td,{children:"message type: MEMBER, APP, SYSTEM"}),(0,s.jsx)(n.td,{children:"MEMBER: sending by member, APP: sending by app, SYSTEM: sending by system"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"appUserId"}),(0,s.jsx)(n.td,{children:"user ID"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"appUsername"}),(0,s.jsx)(n.td,{children:"username"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"customType"}),(0,s.jsx)(n.td,{children:"Custom types to distinguish messages"}),(0,s.jsx)(n.td,{children:'If origin is of type SYSTEM, it can be "JOINED", "LEFTED", or "CHANNEL_STAT_UPDATED".'})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"message"}),(0,s.jsx)(n.td,{children:"User-sent messages"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"participantCount"}),(0,s.jsx)(n.td,{children:"Number of participants"}),(0,s.jsx)(n.td,{})]})]})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"7-ending-live-streaming",children:"7. Ending Live Streaming"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"When we want to end the live, we call the stop() and exit() functions to end the broadcast."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// stop streaming\nstreamer?.stop()\n// close chatting\nstreamer?.exit()\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"8-watching-live",children:"8. Watching Live"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["As a prelude to live viewing, you will need the following four values The access token can be obtained through the application server as described in section 1.3 above. The remaining items can be obtained through FlipFlop Lite's ",(0,s.jsx)(n.a,{href:"https://jocoos-public.github.io/dev-book/jekyll/2023-10-16-Member-VideoRoom-API.html#get-videorooms",children:"FlipFlop Cloud - Member Get VideoRooms API"}),". These values are also not provided directly by the SDK, so like the access token, they must be obtained directly through the application server and passed to the client for use."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"access token, video room id, channel id, live url"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Create a StreamingViewFragment class for the screen you're watching live, and a streaming_view_fragment.xml for its View."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"In streaming_view_fragment.xml, we create a View, FFLLiveView, for live viewing."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0" encoding="utf-8"?>\n<androidx.constraintlayout.widget.ConstraintLayout\n   xmlns:android="http://schemas.android.com/apk/res/android"\n   xmlns:app="http://schemas.android.com/apk/res-auto"\n   xmlns:tools="http://schemas.android.com/tools"\n   android:layout_width="match_parent"\n   android:layout_height="match_parent">\n\n  <com.jocoos.flipflop.view.FFLLiveView\n     android:id="@+id/livePlayerView"\n     android:layout_width="match_parent"\n     android:layout_height="match_parent"\n     android:background="@color/black"\n     app:layout_constraintBottom_toBottomOf="parent"\n     app:layout_constraintTop_toTopOf="parent" />\n\n</androidx.constraintlayout.widget.ConstraintLayout>\n\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"In the StreamingViewFragment, we create an FFLLivePlayer instance that we use for live viewing."}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"For live viewing, the SDK provides FFLLivePlayer. With FFLLivePlayer, you can easily watch live and send and receive chat messages."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"When creating an instance, you'll need user information, access token, video room ID, and channel ID."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingViewFragment : Fragment() {\n    private var _binding: StreamingViewFragmentBinding? = null\n    private val binding get() = _binding!!\n    \n    private var player: FFLLivePlayer? = null\n    \n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        val streamer = FlipFlopLite.getLivePlayer(ACCESS_TOKEN, VIDEOROOM_ID, CHANNEL_ID)\n    }\n}\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The StreamingViewFragment uses a ViewBinding to associate with streaming_view_fragment.xml and calls the prepare() function for initialization."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingViewFragment : Fragment() {\n    private var _binding: StreamingViewFragmentBinding? = null\n    private val binding get() = _binding!!\n \n    private var player: FFLLivePlayer? = null\n \n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n            val streamer = FlipFlopLite.getLivePlayer(ACCESS_TOKEN, VIDEOROOM_ID, CHANNEL_ID).apply {\n            prepare(requireContext(), binding.livePlayerView)\n        }\n    }\n}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:'Connect events that occur during live viewing. In this tutorial, we\'ll connect the PlayerStateChanged related to watching live. For more information on the individual items, please refer to the "Handling Event" part.'}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The PlayerStateChanged event notifies you that the state of a player watching your live has changed."}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"event"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"PlayerStateChanged"}),(0,s.jsx)(n.td,{children:"notify that the status of a player watching your live has changed."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"BroadcastStateChanged"}),(0,s.jsx)(n.td,{children:"notify that the live status of the media streaming."})]})]})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The contents of the PlayerState in the PlayerStateChangd event are as follows"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"state"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"PREPARED"}),(0,s.jsx)(n.td,{children:"notify ready to watch live."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"STARTED"}),(0,s.jsx)(n.td,{children:"notify that you started watching live."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"BUFFERING"}),(0,s.jsx)(n.td,{children:"notify that you were paused live viewing."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"STOPPED"}),(0,s.jsx)(n.td,{children:"notify that you stopped live watching"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"COMPLETED"}),(0,s.jsx)(n.td,{children:"notify that live has been finished"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CLOSED"}),(0,s.jsx)(n.td,{children:"notify that you ended live watching"})]})]})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The BroadcastState in the BroadcastStateChanged event has the following contents"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"state"}),(0,s.jsx)(n.th,{children:"description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"ACTIVE"}),(0,s.jsx)(n.td,{children:"notify you that the live is in progress (meaning viewers can see the live)."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"INACTIVE"}),(0,s.jsx)(n.td,{children:"notify you that your live has been interrupted (meaning viewers are unable to watch your live)."})]})]})]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingViewFragment : Fragment() {\n    private var player: FFLLivePlayer? = null\n    \n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        val streamer = FlipFlopLite.getLivePlayer(ACCESS_TOKEN, VIDEOROOM_ID, CHANNEL_ID).apply {\n            prepare(requireContext(), binding.livePlayerView)\n        }\n        \n        lifecycleScope.launch {\n            player?.livePlayerEvent?.collect { event ->\n                when (event) {\n                    is PlayerEvent.PlayerStateChanged -> {\n                        when (event.state) {\n                            PlayerState.PREPARED -> {\n                                // player is prepared\n                            }\n                            PlayerState.STARTED -> {\n                                // player is started\n                            }\n                            PlayerState.BUFFERING -> {\n                                // player is buffering\n                            }\n                            PlayerState.STOPPED -> {\n                                // player is stopped\n                            }\n                            PlayerState.CLOSED -> {\n                                // player is closed\n                            }\n                            PlayerState.COMPLETED -> {\n                                // live is completed\n                            }\n                        }\n                    }\n                    is PlayerEvent.BroadcastStateChanged -> {\n                        when (event.state) {\n                            BroadcastState.ACTIVE -> {\n                                // live has been started\n                            }\n                            BroadcastState.INACTIVE -> {\n                                // live has been stopped\n                            }\n                        }\n                    }\n                    is PlayerEvent.PlayerError -> {\n                        // handle error\n                    }\n                }\n            }\n        }\n    }\n}\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Watching Live"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Call FFLLivePlayer's enter() and start() functions to start watching."}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"The reason it's split into two functions, enter() and start(), rather than one function call: so that you can send and receive chat messages before you watch."}),"\n",(0,s.jsx)(n.p,{children:"When they start watching, the PlayerEvent.STARTED event is fired. Because the media server already has a BroadcastState of ACTIVE, the user does not receive an ACTIVE event. If the server's state changes after the user starts watching, you can receive a BroadcastStateChanged event."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// start chatting\nplayer?.enter()\n// start watching live\nplayer?.start()\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Sending and Receiving chatting message"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Send a chat message. This is a suspend function, so you need to call it inside a coroutine."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:'val message = "Hello!"\nplayer?.liveChat().sendMessage(message)\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"To receive a message sent by a user, do the following The message you sent also comes in as a MessageReceived event, so you can verify that the message you sent was sent properly."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"class StreamingViewFragment : Fragment() {\n    ...\n\n    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {\n        ...\n        \n        lifecycleScope.launch {\n            player?.playerEvent.collect { event ->\n                when (event) {\n                    ...\n                    is PlayerEvent.MessageReceived -> {\n                        handleMessage(event.message)\n                    }\n                    ...\n                }\n            }\n        }\n    }\n    \n    private fun handleMessage(message: FFLMessage) {\n        when (message.origin) {\n            Origin.MEMBER -> {\n                // message sent by user\n            }\n            else -> {\n                // ignore at the moment\n            }\n        }\n    }\n}\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Ending Live Watching"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Call the stop() and exit() functions to end the watch"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-kotlin",children:"// stop watching live\nplayer?.stop()\n// close chatting\nplayer?.exit()\n"})}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>l});var t=i(6540);const s={},r=t.createContext(s);function a(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);